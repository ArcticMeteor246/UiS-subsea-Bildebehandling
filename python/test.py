import math
from re import A
import cv2
from cv2 import StereoBM
from cv2 import mean
import numpy as np
import time
from sys import platform
from common import Cursor
import matplotlib
matplotlib.use('Qt5Agg')
import matplotlib.pyplot as plt
import statistics
from focusvindu import Ui_Auto_focus_settings
from PyQt5 import (QtGui, QtWidgets)
from PyQt5.QtWidgets import (QMainWindow, QFileDialog, )
import sys
from PyQt5.QtWidgets import QApplication
import threading
import torch
#sys.path.insert(1, f'{realpath(".")}/yolov5/')
sys.path.insert(1, f'/home/christoffer/yolov5/')
from models.common import DetectMultiBackend
from utils.datasets import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams
from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,
                           increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh)
from utils.plots import Annotator, colors, save_one_box
from utils.torch_utils import select_device, time_sync
from utils.augmentations import letterbox


class Object(): # Used in functions to draw on image, find distance to objects etc, refers to objects in pictures
    def __init__(self, xyxy:list, name:str, colour:tuple, confidence:float) -> None:
        self.rectangle = [(int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3]))]
        self.angle = 0
        self.box = 0 #[np.int0(cv2.boxPoints(self.rectanlge))] # Added into a list due to easier use in draw contours
        self.width = (self.rectangle[1][0] - self.rectangle[0][0]) # Calulates and set width
        self.height = (self.rectangle[1][1] - self.rectangle[0][1]) # Calulates and set height
        self.position = (int(self.rectangle[0][0] + self.width/2), int(self.rectangle[0][1] + self.height/2)) # Calulates and set center
        self.true_width = 0 # Needs to be calulated using another picture and compare positions
        self.areal = self.width*self.height
        self.dept = 0
        #self.name = f'{name}, confidence:{round(float(confidence.cpu().numpy()), 2)}'
        self.name = name
        self.draw_line_width = 2
        self.colour = colour
        self.confidence = confidence

    @property
    def get_box(self):
        return self._box

    @property
    def get_rectangle(self):
        return self._rectanlge

    @property
    def get_position(self):
        return self._position
    
    @property
    def get_width(self):
        return self._width

    @property
    def get_height(self):
        return self._height

    @property
    def get_areal(self):
        return self._areal

    @property
    def get_dept(self):
        return self._dept

    def set_dept(self, newdept):
        self._dept = int(newdept)

    @property
    def get_true_width(self):
        return self._true_width

    def set_true_width(self, newwidth):
        self._true_width = newwidth

class Camera():
    def __init__(self, id:int, width:int=2560, height:int=720, framerate:int=30 ) -> None:
        self.id = id
        self.height = height
        self.middley = int(height/2) # Center of picture y cord
        self.width = width
        self.hud = False
        tru_width = int(width/2)
        self.length = int(width/18) # Long horisontal line for pitch
        self.length2 = int(width/22) # Short horisontal line for pitch
        self.length3 = int(width/36) # Cursor length
        self.length4 = int(self.length3/4) # Cursor spacing and triangle side length
        self.center = (width/4, height/2) # Center of picture
        self.squarestart = [int(self.center[0]-self.length-self.length4-100), int(self.center[1]-self.length)]
        self.squarestop = [int(self.center[0]-self.length-self.length4-60), int(self.center[1]+self.length)]
        self.cursor = Cursor(self.length3, self.length4, self.center)
        self.left = int(width/4-self.length3/2)
        self.right = int(width/4+self.length3/2)
        self.color = (0, 255, 0)
        self.sensor = {"gyro": (0, 0, 0)}
        if platform == "linux" or platform == "linux2":
            self.feed = cv2.VideoCapture(self.id, cv2.CAP_V4L2)
        else:
            self.feed = cv2.VideoCapture(self.id)
        self.set_picture_size(self.width, self.height)
        self.feed.set(cv2.CAP_PROP_FPS, framerate)
        #self.feed.set(cv2.CAP_PROP_AUTOFOCUS, 3)
         
        #self.feed.set(cv2.CAP_PROP_CONTRAST , -20)
        #self.feed.set(cv2.CAP_PROP_AUTO_EXPOSURE, 1)
        #self.feed.set(cv2.CAP_PROP_EXPOSURE, 50)
        #self.feed.set(cv2.CAP_PROP_AUTO_WB, 1)
        print(self.feed.get(cv2.CAP_PROP_FPS))

    def set_picture_size(self, width:int=2560, height:int=960):
        self.feed.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))
        self.feed.set(cv2.CAP_PROP_FRAME_WIDTH, self.width)
        self.feed.set(cv2.CAP_PROP_FRAME_HEIGHT, self.height)
        self.height = int(self.feed.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.width = int(self.feed.get(cv2.CAP_PROP_FRAME_WIDTH))
        print(f'{self.width}:{self.height}')
        self.crop_width = int(self.width/2)

    def aq_image(self, double:bool=False, t_pic:bool=False):
        #ref, frame = self.feed.read()
        #frame = cv2.rotate(frame, cv2.ROTATE_180)
        #ref, frame = self.feed.read()
        ref = self.feed.grab()
        if ref:
            _, frame = self.feed.retrieve(0)
        else:
            if double:
                return False, False
            else:
                print(time.asctime())
                return False
        if frame is None:
            if double:
                return False, False
            else:
                print(time.asctime())
                return False
        #frame = cv2.rotate(frame, cv2.ROTATE_180)
        crop = frame[:self.height, :self.crop_width]
        crop2 = frame[:self.height,self.crop_width:]
        if t_pic:
            t = time.asctime()
            cv2.imwrite(f'/home/subsea/Bilete/rov/pic_left{t}.png',crop)
            cv2.imwrite(f'/home/subsea/Bilete/rov/pic_right{t}.png', crop2)
        if double:
            crop2 = frame[:self.height,self.crop_width:]
            return crop, crop2
        else:
            return crop

    ## Draws on image
    def draw_on_img(self, pic, frames):
        if isinstance(frames, list):
            if frames != []:
                for item in frames: # Draws objects on picture
                    cv2.rectangle(pic, item.rectangle[0], item.rectangle[1], item.colour, item.draw_line_width) # Draws rectablge on picture
                    pos = (item.rectangle[0][0], item.rectangle[0][1]+40) # For readability
                    cv2.putText(pic, item.name, pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3) # Red text
                    cv2.putText(pic, item.name, pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 1) # White background
                    if item.dept != 0: # Draws dept esitmation if there is one
                        cv2.putText(pic, f'Distance:{int(item.dept)} cm',item.position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 3, cv2.LINE_AA)
                        cv2.putText(pic, f'Distance:{int(item.dept)} cm',item.position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)
        if self.hud:
            self.draw_hud(pic)
    
    def draw_hud(self, pic):
        for a in range(-20,21, 5):
            off = int(self.sensor['gyro'][2]*20+a*20 + self.middley)
            if 0 < off < self.height:
                if(a%2==0):
                    length = self.length
                else:
                    length = self.length2
                cv2.line(pic, (self.right, off), (self.right+length, off), self.color, 2) # 20 deg right
                cv2.putText(pic, f'{a}', (int(self.right+length+10), int(off+5)), cv2.FONT_HERSHEY_SIMPLEX, 1, self.color, 2) # 20 deg right text
                cv2.line(pic, (self.left-length, off), (self.left, off), self.color, 2) # 20 deg left
                #cv2.putText(pic, f'{a}', (self.left-length-45, off+5), cv2.FONT_HERSHEY_SIMPLEX, 1, self.color, 2) # 20 deg left text
        dept = self.sensor['gyro'][0]
        dept = 2400
        
        cv2.rectangle(pic, self.squarestart, self.squarestop, self.color, 2)
        cv2.putText(pic, f'Depth', (int(self.squarestart[0]-10) ,int(self.squarestart[1]-10)), cv2.FONT_HERSHEY_SIMPLEX, 1, self.color, 2)
        
        offset = int(dept+10 - math.floor(dept/10)*10)
        dep_text = int(int(dept/10)*10)
        for a in range(100 , 0 , -10):
            cv2.line(pic, (int(self.squarestart[0]+4), int(self.squarestart[1]+a*3+offset)), (int(self.squarestop[0]-4), int(self.squarestart[1]+a*3+offset)), self.color, 2)
            if a != 50 and a != 0:
                space = len(f'{(a-50+dep_text)}')
                cv2.putText(pic, f'{(a-50+dep_text)}', (int(self.squarestart[0]-space*15-30), int(self.squarestart[1]+a*3+offset+5)), cv2.FONT_HERSHEY_SIMPLEX, 1, self.color, 2)
        space = len(f'{(dept)}')
        
        points = np.array(self.cursor.get_points(self.sensor['gyro'][1]))
        cv2.polylines(pic, [points], False, (0,0,255), 2)
        cv2.putText(pic, f'{dept}', (int(self.squarestart[0]-space*15-30), int(self.center[1]+5)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)
        cv2.line(pic, (int(self.squarestart[0]+4), int(self.center[1])), (int(self.squarestop[0]-4), int(self.center[1])), (0,0,255), 2)

    def update_data(self, sens):
        self.sensor = sens

class Athena(): 
    def __init__(self) -> None:
        self.orb = cv2.ORB_create()
        self.bf = cv2.BFMatcher.create(cv2.NORM_HAMMING, crossCheck=True )
        self.first = True
        self.old_object_list = []
        self.first_width = True
        self.old_width_list = []
        
    # Diffrent methods to compare pixels in multiple pictures
    #stereo = cv2.StereoBM_create(numDisparities=16, blockSize=9)
    # 1
    #sift = cv2.SIFT_create()
    
    # 2
    #orb = cv2.ORB_create()
    #bf = cv2.BFMatcher()# OLD VERSION, THX OPENCV
    #bf = cv2.BFMatcher.create(cv2.NORM_HAMMING, crossCheck=True )

    # 3
    #cv2.FlannBasedMatcher(index_paralgorithm = 1, trees = 5, checks = 50) # index_paralgorithm = FLANN_INDEX_KDTREE = 1
    def check_last_size(self, new_object_list):
        if self.first:
            self.first = False
            self.old_object_list = new_object_list
            return new_object_list
        if len(new_object_list) == len(self.old_object_list):
            for a, obj in enumerate(new_object_list): # Checks each object if its within 20% of old size and position
                if self.old_object_list[a].width*0.8 < obj.width < self.old_object_list[a].width*1.2:
                    #if self.old_object_list[a].position[0]*0.8 < obj.position[0] < self.old_object_list[a].position[0]*1.2:
                    if obj.dept <= 0:
#                        ln(f"{obj.dept}, {self.old_object_list[a].dept}")
                        obj.dept = self.old_object_list[a].dept
                    elif self.old_object_list[a].dept <= 50:
                        pass
                    else:
 #                       ln(f"{obj.dept}, {self.old_object_list[a].dept}")
                        obj.dept = self.old_object_list[a].dept*0.8 + obj.dept*0.2
        elif len(new_object_list) == 0 and len(self.old_object_list) != 0:
            return self.old_object_list
        self.old_object_list = new_object_list
        return self.old_object_list

    def check_width(self, new_object_list:list):
        if self.first_width:
            self.old_width_list = new_object_list
            return new_object_list
        else:
            if len(new_object_list) == len(self.old_width_list):
                for a, obj in enumerate(new_object_list):
                    if self.old_object_list[a].name == obj.name:
                        if self.old_object_list[a].width*0.8 < obj.width < self.old_object_list[a].width*1.2:
                            if obj.true_width <= 0:
                                obj.true_width = self.old_object_list[a].true_width
                            else:
                                obj.true_width = self.old_object_list[a].true_width*0.8 + obj.true_width*0.2
        return self.old_object_list

    def compare_pixles(self, object_list1, object_list2, pic):
        gray = [cv2.cvtColor(pic[0], cv2.COLOR_BGR2GRAY), cv2.cvtColor(pic[1], cv2.COLOR_BGR2GRAY)]
        new_object_list = []
        for obj1 in object_list1:
            for obj2 in object_list2:
                if obj1.position[1]-100 <= obj2.position[1] <= obj1.position[1]+100:
                    if obj1.width-50 <= obj2.width <= obj1.width+50:
                        points = [] # points to crop
                        points.append(int(obj1.rectangle[0][1]-obj1.height*0.1)) 
                        points.append(int(obj2.rectangle[0][1]-obj2.height*0.1)) 
                        points.append(int(obj1.rectangle[0][1]+obj1.height*1.1)) 
                        points.append(int(obj2.rectangle[0][1]+obj2.height*1.1)) 
                        points.append(int(obj1.rectangle[0][0]-obj1.width*0.1)) 
                        points.append(int(obj2.rectangle[0][0]-obj1.width*0.1)) 
                        points.append(int(obj1.rectangle[0][0]+obj1.width*1.1)) 
                        points.append(int(obj2.rectangle[0][0]+obj1.width*1.1)) 
                        for b, a in enumerate(points): # Checks that all points are within picture before crop
                            if a < 0:
                                points[b] = 0
                            if b <= 3:
                                if a > 720:
                                    points[b] = 720
                            else:
                                if a > 1280:
                                    points[b] = 1280
                        crop1 = gray[0][points[0]:points[2], points[4]:points[6]]
                        crop2 = gray[1][points[1]:points[3], points[5]:points[7]]
                        offset = obj1.rectangle[0][0]- obj2.rectangle[0][0]

                        # Testprints
                        #print(f'pos0:{int(obj1.rectangle[0][0])}')
                        #print(f'pos1:{int(obj1.rectangle[0][1])}')
                        #a = int(obj1.rectangle[0][0]+obj1.height*0.2)-int(obj2.rectangle[0][0]+obj1.height*0.2)
                        #b = obj1.rectangle[0][0]- obj2.rectangle[0][0]
                        #print(f'{(a==b)}')
                        #print(f'Offset:{offset}')
                        #print(f'Width1:{obj1.width}, height1:{obj1.height}')
                        #print(f'Width2:{obj2.width}, height2:{obj2.height}')
                        #cv2.imshow("TAGE1!!!!", crop1)
                        #cv2.imshow("TAGE2!!!!", crop2)
                        #if cv2.waitKey(1) & 0xFF == ord('q'):
                        #        break
                        
                        kp1, des1 = self.orb.detectAndCompute(crop1 ,None)
                        kp2, des2 = self.orb.detectAndCompute(crop2 ,None)
                        try:
                            mached_pixels = self.bf.match(des1, des2)
                            mached_pixels = sorted(mached_pixels, key = lambda x:x.distance)
                            print(len(mached_pixels))
                            new_list = []
                            for a in mached_pixels:
                                if a.distance < 100:
                                    new_list.append(a)
                        except Exception as i:
                            print(i)
                            return
                        mached_pixels = new_list
                        #imgDummy = np.zeros((1,1))
                        #img = cv2.drawMatches(crop1,kp1,crop2,kp2,mached_pixels[:10], imgDummy, flags=2)
                        #cv2.imshow("TAGE1!!!!", img)
                        dif_list = []
                        if len(mached_pixels) > 2:
                            for a in mached_pixels:
                                if abs(kp1[a.queryIdx].pt[1] - kp2[a.trainIdx].pt[1]) < 10:
                                    crop1 = cv2.circle(crop1, (int(kp1[a.queryIdx].pt[0]), int(kp1[a.queryIdx].pt[1])), 4, (255,0,0), -1)
                                    crop2 = cv2.circle(crop2, (int(kp2[a.trainIdx].pt[0]), int(kp2[a.trainIdx].pt[1])) , 4, (255,0,0), -1)
                                    dif_list.append(abs(kp1[a.queryIdx].pt[0] - kp2[a.trainIdx].pt[0]+offset))
                            if len(dif_list) > 2:   
                                med = statistics.median(dif_list)
                                if 158 < med < 218:
                                    obj1.dept = calc_distance(med)
                                    ln(f"{obj1.dept}")
                                
                                # Print for calibration
                                #print(f'Disparity: {statistics.median(dif_list)}')
                                
                                #cv2.imshow("TAGE1!!!!", crop1)
                                #cv2.imshow("TAGE2!!!!", crop2)
                                #if cv2.waitKey(1) & 0xFF == ord('q'):
                                #    break
                                #pass
                                #print(f'Mean:{statistics.mean(dif_list)}')
                                #print(f'Median:{statistics.median(dif_list)}')
                        #plt.imshow(img),plt.show()
                        #cv2.imshow("TAGE2!!!!", crop2)
                        #if cv2.waitKey(1) & 0xFF == ord('q'):
                        #    break
            new_object_list.append(obj1)
        if len(new_object_list) > 1:
            new_object_list = check_overlap(new_object_list) # Checks for object overlapping
        new_object_list = self.check_last_size(new_object_list) # Filters distances vales, and sets old if new is not found
        return new_object_list


class Yolo(): # 
    def __init__(self, resol, name:str = 'Rubberfish') -> None:
        self.device = select_device('') # Finds possible hardware to use
        print(self.device)
        self.weights = 'yolov5/models/rubber5.pt' # Used machine learning
        self.data = 'yolov5/data/coco128.yaml' 
        self.conf_trees = 0.40 # How high confedence we want for a match
        self.iou_tres = 0.45 
        self.color = (255, 0, 0) # Color for frames drawn around object
        self.text = name # Text drawn on picture
        self.model = DetectMultiBackend(self.weights, self.device, False, self.data,)
        imgsz=[640, 640] # Size of pic samples
        self.resolution = resol # Image resolution
        self.imgsz = check_img_size(imgsz, s=self.model.stride)
        tride, self.names, pt, jit, onnx, engine = self.model.stride, self.model.names, self.model.pt, self.model.jit, self.model.onnx, self.model.engine
        if pt or jit:
            self.model.model.float()
        self.model.warmup(imgsz=(1, 3, *imgsz))
        self.resize = [float(resol[1])/384, float(resol[0])/640]
        

    def yolo_image(self, image, test = False): #Find shapes using YOLO (Mostly fish)
        shape = image.shape
        gn = torch.tensor(image.shape)[[1, 0, 1, 0]]  # normalization gain whwh
        image = letterbox(image, self.imgsz, stride=self.model.stride, auto=True)[0]
        image = image.transpose((2, 0, 1))[::-1] # Transpose picture from BGR to RGB, torch needs RGB
        image = np.ascontiguousarray(image) # Numpy magic
        image = torch.from_numpy(image).to(self.device) # Everything is faster with torch
        image = image.float() # Float to later devide color data
        image /= 255
        if len(image.shape) == 3: 
            image = image[None] # Adds element to start of list
        pred = self.model(image, augment=False, visualize=False)
        pred = non_max_suppression(pred, self.conf_trees)
        
        detected_list = []
        for i, detected in enumerate(pred):
            for *xyxy, conf, cls in reversed(detected):
                wx = (torch.tensor(xyxy).view(1, 4))
                wx = self.resize_square(wx[0])
                detected_list.append(Object(wx, self.names[int(cls)], self.color, conf))
        return detected_list


    def resize_square(self, xyxy:list):
        xyxy = xyxy.numpy()
        c = 1
        for a, b in enumerate(xyxy):
            xyxy[a] = b*self.resize[c]
            c += 1
            if c > 1:
                c = 0
        return xyxy


def draw_on_img(pic, frames):
    if isinstance(frames, list):
        if frames != []:
            for item in frames: # Draws objects on picture
                cv2.rectangle(pic, item.rectangle[0], item.rectangle[1], item.colour, item.draw_line_width) # Draws rectablge on picture
                pos = (item.rectangle[0][0], item.rectangle[0][1]+40) # For readability
                cv2.putText(pic, item.name, pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3) # Red text
                cv2.putText(pic, item.name, pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 1) # White background
                if item.true_width != 0: # Draws dept esitmation if there is one
                    cv2.putText(pic, f'Width: {int(item.true_width)} cm',item.position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 3, cv2.LINE_AA)
                    cv2.putText(pic, f'Width: {int(item.true_width)} cm',item.position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)

def check_objects_calc_size(objects):
    rubber_list = {"rubberfish":[], "head":[], "tail":[]}
    out = []
    
    for a in objects:
        if str(a.name).lower() in rubber_list.keys():
            rubber_list[str(a.name).lower()].append(a)

    for key in rubber_list.keys():
        if len(rubber_list[key]) > 1:
            rubber_list[key] = check_overlap(rubber_list[key])
    if len(rubber_list["rubberfish"]) > 0 and len(rubber_list["head"]) > 0 and len(rubber_list["tail"]) > 0:
        for fish in rubber_list["rubberfish"]:
            temp_list = []
            for head in rubber_list["head"]:
                if is_overlap(head.position, fish.rectangle):
                    temp_list.append(head)
                    break
            if len(temp_list) > 0:
                for tail in rubber_list["tail"]:
                    if is_overlap(tail.position, fish.rectangle):
                        temp_list.append(tail)
                        break
            if len(temp_list) == 2:
                fish.true_width = calc_size_fish(temp_list)

    return rubber_list["rubberfish"]

def find_horizontal_line(matri): # Returns the ypos with the most white pixels from a bitmap picture
    big = 200000
    ypos = 0
    for a in range(int(len(matri/10))):
        temp = np.sum(matri[a*10:10+a*10])
        if temp > big:
            big = temp
            ypos = 10*a
    if not ypos==0:
        print(big)
        return ypos
    else:
        return False

def find_vertical_line(matri): # Returns the xpos with the most white pixels from a bitmap picture
    big = 200000
    xpos = 0
    for a in range(int(len(matri[0]/10))):
        temp = np.sum(matri[:, a*10:10+a*10])
        if temp > big:
            big = temp
            xpos = 10*a
    if not xpos == 0:
        return xpos
    else:
        return False

def to_bitmap(pic, masks):
        pic = cv2.GaussianBlur(pic,(25,25),0) # Filter image for better results
        hsv = cv2.cvtColor(pic, cv2.COLOR_BGR2HSV)
        mask = cv2.inRange(hsv, masks[0], masks[1])
        mask2 = cv2.inRange(hsv, masks[2], masks[3])
        _, tempblack = cv2.threshold(pic, 70, 255, cv2.THRESH_BINARY)
        canvas = np.zeros(tempblack.shape, np.uint8) # Heil svart maske
        mas2 = cv2.bitwise_or(mask, mask2, canvas)
        kernel = np.ones((5,5),np.uint8)
        mas2 = cv2.dilate(mas2, kernel, iterations = 1)
        return mas2

def merd_yaw(pic1, pic2, orb):
        pic1 = cv2.GaussianBlur(pic1,(25,25),0)
        pic2 = cv2.GaussianBlur(pic2,(25,25),0)
        pic1 = cv2.cvtColor(pic1, cv2.COLOR_BGR2GRAY)
        pic2 = cv2.cvtColor(pic2, cv2.COLOR_BGR2GRAY)
        kp1, des1 = orb.detectAndCompute(pic1 ,None)
        kp2, des2 = orb.detectAndCompute(pic2 ,None)
        failed = False
        a92 = 0
        try:
            mached_pixels = bf.match(des1, des2)
        except Exception as e:
            failed = True
        if not failed:
            mached_pixels = sorted(mached_pixels, key = lambda x:x.distance)
            #print(len(mached_pixels))
            dobbel_list = [[],[]]
            if len(mached_pixels) > 2:
                for a in mached_pixels:
                    if abs(kp1[a.queryIdx].pt[1] - kp2[a.trainIdx].pt[1]) < 15:
                        pic1 = cv2.circle(pic1, (int(kp1[a.queryIdx].pt[0]), int(kp1[a.queryIdx].pt[1])), 4, (255,0,0), -1)
                        pic1 = cv2.circle(pic1, (int(kp2[a.trainIdx].pt[0]), int(kp2[a.trainIdx].pt[1])) , 4, (255,0,0), -1)
                        if kp1[a.queryIdx].pt[0] < 640:
                            dobbel_list[0].append(abs(kp1[a.queryIdx].pt[0] - kp2[a.trainIdx].pt[0]))
                        else:
                            dobbel_list[1].append(abs(kp1[a.queryIdx].pt[0] - kp2[a.trainIdx].pt[0]))
            if len(dobbel_list[0]) > 1 and len(dobbel_list[1]) > 1:
                a92 = statistics.mean(dobbel_list[0])-statistics.mean(dobbel_list[1])
            return a92
        else:
            return False

class Maske_gui(QtWidgets.QDialog, Ui_Auto_focus_settings):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setupUi(self)
        self.parameters = {
            'h1':0 ,
            's1':80 ,
            'v1':140 ,
            '1_upper':18 ,
            'h2':166 ,
            's2':155 ,
            'v2':121 ,
            '2_upper':180 ,
        }
        self.Pink_slider_1.actionTriggered.connect(lambda: self.change_value(self.Pink_slider_1, self.Pink_spin_1, 'h1'))
        self.Pink_slider_2.actionTriggered.connect(lambda: self.change_value(self.Pink_slider_2, self.Pink_spin_2, 's1'))
        self.Pink_slider_3.actionTriggered.connect(lambda: self.change_value(self.Pink_slider_3, self.Pink_spin_3, 'v1'))
        self.Pink_slider_4.actionTriggered.connect(lambda: self.change_value(self.Pink_slider_4, self.Pink_spin_4, '1_upper'))
        self.Pink_slider_5.actionTriggered.connect(lambda: self.change_value(self.Pink_slider_5, self.Pink_spin_5, 'h2'))
        self.Pink_slider_6.actionTriggered.connect(lambda: self.change_value(self.Pink_slider_6, self.Pink_spin_6, 's2'))
        self.Pink_slider_7.actionTriggered.connect(lambda: self.change_value(self.Pink_slider_7, self.Pink_spin_7, 'v2'))
        self.Pink_slider_8.actionTriggered.connect(lambda: self.change_value(self.Pink_slider_8, self.Pink_spin_8, '2_upper'))
        self.Pink_spin_1.valueChanged.connect(lambda: self.change_value_spin(self.Pink_spin_1, self.Pink_slider_1, 'h1'))
        self.Pink_spin_2.valueChanged.connect(lambda: self.change_value_spin(self.Pink_spin_2, self.Pink_slider_2, 's1'))
        self.Pink_spin_3.valueChanged.connect(lambda: self.change_value_spin(self.Pink_spin_3, self.Pink_slider_3, 'v1'))
        self.Pink_spin_4.valueChanged.connect(lambda: self.change_value_spin(self.Pink_spin_4, self.Pink_slider_4, '1_upper'))
        self.Pink_spin_5.valueChanged.connect(lambda: self.change_value_spin(self.Pink_spin_5, self.Pink_slider_5, 'h2'))
        self.Pink_spin_6.valueChanged.connect(lambda: self.change_value_spin(self.Pink_spin_6, self.Pink_slider_6, 's2'))
        self.Pink_spin_7.valueChanged.connect(lambda: self.change_value_spin(self.Pink_spin_7, self.Pink_slider_7, 'v2'))
        self.Pink_spin_8.valueChanged.connect(lambda: self.change_value_spin(self.Pink_spin_8, self.Pink_slider_8, '2_upper'))
        self.img = cv2.imread('blank.jpg')
        self.startup_positons()
        threading.Thread(name="COM_cam_1",target=mask_pic, daemon=True, args=(self.parameters, self.img)).start()
    
    def startup_positons(self):
        self.Pink_spin_1.setValue(self.parameters['h1'])
        self.Pink_spin_2.setValue(self.parameters['s1'])
        self.Pink_spin_3.setValue(self.parameters['v1'])
        self.Pink_spin_4.setValue(self.parameters['1_upper'])
        self.Pink_spin_5.setValue(self.parameters['h2'])
        self.Pink_spin_6.setValue(self.parameters['s2'])
        self.Pink_spin_7.setValue(self.parameters['v2'])
        self.Pink_spin_8.setValue(self.parameters['2_upper'])

    def change_value(self, slider, spin, index, div=0):
        div = 10 ** div
        if div == 1:
            self.parameters[index] = slider.sliderPosition()
        else:
            self.parameters[index] = slider.sliderPosition() / div
        spin.setValue(self.parameters[index])

    def change_value_spin(self, spin, slider, index, mult=0):
        mult = 10 ** mult
        self.parameters[index] = spin.value()
        if mult == 1:
            slider.setSliderPosition(int(self.parameters[index]))
        else:
            slider.setSliderPosition(int(self.parameters[index] * mult))
    
def mask_pic(parameters, img):
    while True:
        temp = np.copy(img)
        lower_2 = np.array([parameters['h1'], parameters['s1'], parameters['v1']])
        upper_2 = np.array([parameters['1_upper'],255,255])
        lower_red = np.array([parameters['h2'],155,121])
        upper_red = np.array([180,255,255])
        masks = [lower_2, upper_2, lower_red, upper_red]
        temp = to_bitmap(temp, masks)
        cv2.imshow('frame', temp)
        cv2.waitKey(50) # waits until a key is pressed
    cv2.destroyAllWindows() # destroys the window showing image

def check_overlap(obj_list): 
    del_list = []
    for a, b in enumerate(obj_list):
        if a != len(obj_list)-1:
            for obj in obj_list[a+1:]:
                if is_overlap(b.position, obj.rectangle):
                    del_list.append(b)
                    break
    for a in del_list:
        obj_list.remove(a)
    return obj_list

def is_overlap(center, box):
    # a-------+
    # |       |
    # +-------b
    a_x, a_y = box[0][0], box[0][1]
    b_x, b_y = box[1][0], box[1][1]
    center_x, center_y = center[0], center[1]

    return True if a_x < center_x < b_x and a_y < center_y < b_y else False

def calc_size_fish(fishlist):
    # fishlist is always 2 items, [head, tail]
    head_tail_width = fishlist[0].width + fishlist[1].width
    true_width = 34 #cm = 33

    # Head is left
    if fishlist[0].position[0] < fishlist[1].position[0]:
        pix_total_width = fishlist[1].rectangle[1][0] - fishlist[0].rectangle[0][0]

    # Tail is left
    else:
        pix_total_width = fishlist[0].rectangle[1][0] - fishlist[1].rectangle[0][0]

    return true_width * pix_total_width / head_tail_width

def check_objects_calc_size(objects):
    rubber_list = {"rubberfish":[], "head":[], "tail":[]}
    out = []
    
    for a in objects:
        if str(a.name).lower() in rubber_list.keys():
            rubber_list[str(a.name).lower()].append(a)

    for key in rubber_list.keys():
        if len(rubber_list[key]) > 1:
            rubber_list[key] = check_overlap(rubber_list[key])
    if len(rubber_list["rubberfish"]) > 0 and len(rubber_list["head"]) > 0 and len(rubber_list["tail"]) > 0:
        for fish in rubber_list["rubberfish"]:
            temp_list = []
            for head in rubber_list["head"]:
                if is_overlap(head.position, fish.rectangle):
                    temp_list.append(head)
                    break
            if len(temp_list) > 0:
                for tail in rubber_list["tail"]:
                    if is_overlap(tail.position, fish.rectangle):
                        temp_list.append(tail)
                        break
            if len(temp_list) == 2:
                fish.true_width = calc_size_fish(temp_list)

    return rubber_list["rubberfish"]

def main1():
    c = Camera(1)
    orb = cv2.ORB_create()
    bf = cv2.BFMatcher.create(cv2.NORM_HAMMING, crossCheck=True )
    a92, sta1, sta2 = 0,0,0
    lower_2 = np.array([0,80,140])
    upper_2 = np.array([18,255,255])
    lower_red = np.array([166,155,121])
    upper_red = np.array([180,255,255])
    masks = [lower_2, upper_2, lower_red, upper_red]
    while True:
        failed = False
        b1, b2 = c.aq_image(True)
        b1 = cv2.GaussianBlur(b1,(25,25),0)
        hsv = cv2.cvtColor(b1, cv2.COLOR_BGR2HSV)
        b1 = cv2.GaussianBlur(b1,(25,25),0)
        b2 = cv2.GaussianBlur(b2,(25,25),0)
        b12 = cv2.cvtColor(b1, cv2.COLOR_BGR2GRAY)
        b22 = cv2.cvtColor(b2, cv2.COLOR_BGR2GRAY)
        kp1, des1 = orb.detectAndCompute(b12 ,None)
        kp2, des2 = orb.detectAndCompute(b22 ,None)
        try:
            mached_pixels = bf.match(des1, des2)
        except Exception as e:
            failed = True
        if not failed:
            mached_pixels = sorted(mached_pixels, key = lambda x:x.distance)
            #print(len(mached_pixels))
            dobbel_list = [[],[]]
            if len(mached_pixels) > 2:
                for a in mached_pixels:
                    if abs(kp1[a.queryIdx].pt[1] - kp2[a.trainIdx].pt[1]) < 15:
                        b12 = cv2.circle(b12, (int(kp1[a.queryIdx].pt[0]), int(kp1[a.queryIdx].pt[1])), 4, (255,0,0), -1)
                        b22 = cv2.circle(b22, (int(kp2[a.trainIdx].pt[0]), int(kp2[a.trainIdx].pt[1])) , 4, (255,0,0), -1)
                        if kp1[a.queryIdx].pt[0] < 640:
                            dobbel_list[0].append(abs(kp1[a.queryIdx].pt[0] - kp2[a.trainIdx].pt[0]))
                        else:
                            dobbel_list[1].append(abs(kp1[a.queryIdx].pt[0] - kp2[a.trainIdx].pt[0]))
            if len(dobbel_list[0]) > 1 and len(dobbel_list[1]) > 1:
                sta1 = sta1*0.9 + 0.1*statistics.mean(dobbel_list[0])
                sta2 = sta2*0.9 + 0.1*statistics.mean(dobbel_list[1])
                a92 = sta1-sta2
            a92= int(a92*0.95+0.05*(sta1-sta2))
            #print(f"{a92}\t{int(sta1)}\t{int(sta2)}")
            #print(type(statistics.mean(dobbel_list[0])))
            #print(statistics.mean(dobbel_list[0]))
            #print(statistics.mean(dobbel_list[1]))
        #mask = cv2.inRange(hsv, lower_red, upper_red)
        #mask2 = cv2.inRange(hsv, lower_2, upper_2)
        #hsv = cv2.Canny(hsv, 50, 100, apertureSize=3)
        #linjer = cv2.HoughLinesP(hsv, 1, np.pi/180, 100)
        #print(type(linjer))
        #if isinstance(linjer, np.ndarray):
        #    print(len(linjer))
        #if linjer is not None:
        #    for i in range(0, len(linjer)):
        #        l = linjer[i][0]
        #        cv2.line(b1, (l[0], l[1]), (l[2], l[3]), (255,255,255), 3, cv2.LINE_AA)
        #print(len(linjer))
        #print(len(dif_list))
        #for a in dif_list:
        #    print(f'{a}\n')
        #b12 = cv2.threshold(b12, 127, 255, cv2.THRESH_BINARY)
        #asd = cv2.findContours(b12, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        #cv2.drawContours(b1, asd, -1, (255,0,0), 2)
        #_, tempblack = cv2.threshold(b12, 70, 255, cv2.THRESH_BINARY)
        #canvas = np.zeros(tempblack.shape, np.uint8) # Heil svart maske

        #st = cv2.StereoBM_create(numDisparities=16, blockSize=5)
        #st.setTextureThreshold(256)
        #disparity = st.compute(b12,b22)

        #mas2 = cv2.bitwise_or(mask, mask2, canvas)
        #kernel = np.ones((5,5),np.uint8)
        #mas2 = cv2.dilate(mas2, kernel, iterations = 1)
        #print(find_vertical_line(mas2))
        #print(yaw(b1, b2, orb))
        mas2 = to_bitmap(b1, masks)
        hline = find_horizontal_line(mas2)
        vline = find_vertical_line(mas2)
        if hline:
            cv2.line(b1, (0,hline), (1280, hline), (255,255,0), 3)
        if vline:
            cv2.line(b1, (vline, 0), (vline,720), (255,255,0), 3)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
        #plt.imshow(disparity)
        #cv2.imshow('asd', mas2)
        cv2.imshow('asasdd', b1)

        #plt.show()
    cv2.destroyAllWindows()

def main2():
    app = QApplication(sys.argv)
    win = Maske_gui()
    win.show()
    sys.exit(app.exec())

def main3():
    time_list = []
    mode = 1 # 1: Find rubberfish, 2: mosaikk 3:TBA 
    #TODO Her skal autonom kjøring legges inn
    old_list = []
    first = True
    width = 1280
    lower_2 = np.array([0,80,140])
    upper_2 = np.array([18,255,255])
    lower_red = np.array([166,155,121])
    upper_red = np.array([180,255,255])
    masks = [lower_2, upper_2, lower_red, upper_red]
    st_list = [] # List of images to stitch
    ath = Athena()
    new_pic = False
    stitch = False
    orb = cv2.ORB_create()
    cap = cv2.VideoCapture('/media/christoffer/Windows/Skole/video/asd.mp4')
    while (cap.isOpened()):
        ret, img = cap.read()
        if first:
            first = False
            s = img.shape
            yal = Yolo( (1280, 720) )
        if ret == True:
            res1 = yal.yolo_image(img)
            mached_list = check_objects_calc_size(res1)
            mached_list2 = ath.check_width(mached_list)
            good_list = ath.check_width(mached_list2)
            if len(good_list) > 0:
                draw_on_img(img, good_list)
            cv2.imshow('Frame',img)
            if cv2.waitKey(25) & 0xFF == ord('q'):
                break
        else:
            break
    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main3()